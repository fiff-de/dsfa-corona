# DE: Datenschutz-Folgenabschätzung (DSFA) für die Corona-App (EN below)

Seit der Ausbreitung des SARS-CoV-2-Virus in Europa Anfang 2020 wird der Ruf nach technischen Lösungen lauter, die bei der Bekämpfung oder Eindämmung der Pandemie zum Einsatz kommen sollen. Im Zentrum der Debatten stehen Tracing-Apps, die aufgrund der globalen Verbreitung von Smartphones mit der Verheißung aufgeladen werden, die herkömmlichen Verfahren zur Erforschung des epidemiologischen Verlaufs zu unterstützen. Diese Systeme würden automatisiert die zwischenmenschlichen Kontakte aller Nutzerïnnen aufzeichnen und es so erlauben, die Infektionsketten des Virus schnell und effizient auch rückwirkend nachzuvollziehen, um möglicherweise exponierte Personen frühzeitig isolieren zu können. Unter den verschiedenen Systementwürfen stechen jene hervor, die damit werben, datenschutzfreundlich und DSGVO-konform zu sein. Die DSGVO selbst verpflichtet die Betreiberïnnen umfangreicher Datenverarbeitungssysteme (zu denen auch ein Tracing-Apps zählen würden) zur Anfertigung einer Datenschutz-Folgenabschätzung (DSFA) aufgrund des hohen Risikos für die Rechte- und Freiheiten (Art. 35 DSGVO). Hierbei handelt es sich um eine strukturierte Risikoanalyse, die mögliche grundrechtsrelevante Folgen einer Datenverarbeitung im Vorfeld identifiziert und bewertet.

Dieser Text untersucht im Rahmen einer methodisch angeleiteten Datenschutz-Folgeabschätzung in Verbindung mit dem [Standard-Datenschutzmodell (SDM)](https://www.datenschutzzentrum.de/sdm/) im Wesentlichen drei bekannt gewordene Entwürfe, die als die datenschutzfreundlichsten gelten: das [PEPP-PT-Framework](https://www.pepp-pt.org), die [DP-3T-Implementation](https://github.com/DP-3T) und ein vom CCC-Mitglied Linus Neumann [zusammengefasstes Konzept](https://linus-neumann.de/2020/03/corona-apps-sinn-und-unsinn-von-tracking/). Ihnen allen ist die Verarbeitung von Gesundheitsdaten gemein.

Die DSFA beginnt mit einer Analyse der Beschreibung des Verarbeitungskontext und einiger erwartbarer Use Cases. Anschließend wird unter Festlegung eines realistischen Verarbeitungszwecks die Verarbeitungstätigkeiten beschrieben. Danach folgt die rechtliche Bewertung und die Schwellwertanalyse. Den letzten Teil bildet die Analyse von Schwachstellen und Risiken und die Bestimmung von Schutzmaßnahmen. 

In der Untersuchung kommen wir unter anderem zu dem Ergebnis, dass alle Entwürfe wichtige technische Merkmale und Verfahrenseigenschaften offen lassen, die zum Teil mit drastischen datenschutzrelevanten Folgen verbunden sind. Dazu gehört zum Beispiel die architektonische Entscheidung zwischen Zentralität und Dezentralität bei PEPP-PT. 

Zudem zeigen wir, dass auch die dezentrale Implementierung zahlreiche gravierende Schwachstellen und Risiken birgt. Auf der rechtlichen Seite haben wir die Legitimationsgrundlage einer freiwilligen Einwilligung untersucht und formulieren die Erwartung, dass der Einsatz einer Tracing-App gesetzlich geregelt werden muss. Weiterhin konnten wir feststellen, dass Maßnahmen zur Verwirklichung von Betroffenenrechten nicht ausreichend betrachtet wurden. Nicht zuletzt zeigen wir, dass die Behauptung, ein Datum sei anonym, hoch voraussetzungsreich ist. Anonymisierung muss als ein kontinuierlicher Vorgang begriffen werden, der eine Abtrennung des Personenbezugs zum Ziel hat und auf dem Zusammenspiel von rechtlichen, organisatorischen und technischen Maßnahmen beruht. Allen derzeit vorliegenden Vorschlägen fehlt es an einem solchen expliziten Trennungsvorgang.

Weitere Informationen siehe: https://www.fiff.de/presse/dsfa-corona

---

# EN: Data Protection Impact Assessment (DPIA) for the Corona App

Since the SARS-CoV-2 virus spread in Europe in early 2020, there has been a strong outcry for technical solutions to combat or contain the pandemic. At the heart of the debates are tracing apps, which, due to the global distribution of smartphones, are being loaded with the promise of supporting conventional methods for researching the epidemiological course of the disease. These systems would automatically record the interpersonal contacts of all users and thus make it possible to trace the infection chains of the virus quickly and efficiently, also retrospectively, in order to isolate potentially exposed persons at an early stage. Among the various system designs, those that advertise being data protection friendly and GDPR compliant stand out. The GDPR itself requires operators of extensive data processing systems (which would also include a tracing app) to prepare a data protection impact assessment (DPIA) due to the high risk to rights and freedoms (Art. 35 GDPR). This is a structured risk analysis that identifies and evaluates possible consequences of data processing relevant to fundamental rights in advance. 

This text, in the context of a methodologically guided data protection impact assessment in conjunction with the [Standard Data Protection Model (SDM)](https://www.datenschutzzentrum.de/sdm/), essentially examines three known drafts that are considered to be the most privacy-friendly: the [PEPP-PT framework](https://www.pepp-pt.org), the [DP-3T implementation](https://github.com/DP-3T) and a [concept summarized](https://linus-neumann.de/2020/03/corona-apps-sinn-und-unsinn-von-tracking/) by CCC member Linus Neumann. They all process data concerning health.

The DPIA starts with an analysis of the description of the processing context and some expected use cases. Then, the processing activities are described by defining a realistic processing purpose. This is followed by the legal assessment and threshold analysis. The last part is the analysis of weak points and risks and the determination of protective measures.

We also show that even decentralized implementation involves numerous serious weaknesses and risks. On the legal side, we have examined the legitimacy of a voluntary consent and formulate the expectation that a tracing app must process data based on a law. Furthermore, we found that measures to realize the rights of the persons concerned were not sufficiently considered. Last but not least, we show that the assertion that the data can be anonymous is highly presuppositional. Anonymization must be understood as a continuous process, which aims at separating the personal reference and is based on the interaction of legal, organizational and technical measures. All currently available proposals lack such an explicit separation process.

For further information please see: https://www.fiff.de/presse/dsfa-corona
